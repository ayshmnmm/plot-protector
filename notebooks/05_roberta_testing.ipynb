{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/electronic/Downloads/2025H1400069G/plot-protector-as-on-17-11-2025/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (461323, 3)\n",
      "Val shape: (56607, 3)\n",
      "Test shape: (55983, 3)\n",
      "    movie_id                                               text  label\n",
      "0  tt0111161  In its Oscar year, Shawshank Redemption (writt...      1\n",
      "1  tt0111161  The Shawshank Redemption is without a doubt on...      1\n",
      "2  tt0111161  I believe that this film is the best story eve...      1\n",
      "3  tt0111161  **Yes, there are SPOILERS here**This film has ...      1\n",
      "4  tt0111161  At the heart of this extraordinary movie is a ...      1\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed CSVs from the 'without context' directory\n",
    "data_dir = \"../data/de_berta_v3\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "val_df   = pd.read_csv(os.path.join(data_dir, \"val.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape:\",   val_df.shape)\n",
    "print(\"Test shape:\",  test_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 50265\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer for RoBERTa\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "MAX_LEN = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class IMDBSpoilerDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len: int = 256):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text  = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\":      encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\":         torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = IMDBSpoilerDataset(train_df, tokenizer, max_len=MAX_LEN)\n",
    "val_dataset   = IMDBSpoilerDataset(val_df,   tokenizer, max_len=MAX_LEN)\n",
    "test_dataset  = IMDBSpoilerDataset(test_df,  tokenizer, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([16, 256]) torch.int64\n",
      "attention_mask torch.Size([16, 256]) torch.int64\n",
      "labels torch.Size([16]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "NUM_LABELS = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "print(\"Model loaded on:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts: Counter({0: 341802, 1: 119521})\n",
      "Class weights: [0.674839526977607, 1.929882614770626]\n",
      "Total steps: 115332 | Warmup steps: 11533\n"
     ]
    }
   ],
   "source": [
    "# Class weights, optimizer, scheduler\n",
    "from collections import Counter\n",
    "\n",
    "# Compute class weights from train_df\n",
    "label_counts = Counter(train_df[\"label\"].tolist())\n",
    "total = sum(label_counts.values())\n",
    "class_weights = [\n",
    "    total / (NUM_LABELS * label_counts.get(i, 1)) for i in range(NUM_LABELS)\n",
    "]\n",
    "\n",
    "print(\"Label counts:\", label_counts)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "EPOCHS = 4\n",
    "LR = 2e-5\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(WARMUP_RATIO * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"Total steps:\", total_steps, \"| Warmup steps:\", warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_one_epoch(model, data_loader, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    pbar = tqdm(data_loader, desc=\"Train\", leave=False)\n",
    "    for batch in pbar:\n",
    "        input_ids      = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels         = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels_np)\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, acc, f1\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader, desc=\"Eval\", leave=False)\n",
    "        for batch in pbar:\n",
    "            input_ids      = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels         = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "            labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels_np)\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, acc, f1, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4878 | Acc: 0.7767 | F1: 0.4145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.4814 | Acc: 0.7824 | F1: 0.3797\n",
      "Saved best model!\n",
      "\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4554 | Acc: 0.7971 | F1: 0.4947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.4888 | Acc: 0.7889 | F1: 0.4645\n",
      "Saved best model!\n",
      "\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4208 | Acc: 0.8153 | F1: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.4698 | Acc: 0.7852 | F1: 0.5385\n",
      "Saved best model!\n",
      "\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3819 | Acc: 0.8368 | F1: 0.6342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   Loss: 0.5038 | Acc: 0.7844 | F1: 0.5391\n",
      "Saved best model!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(\n",
    "        model, train_loader, optimizer, scheduler, criterion, DEVICE\n",
    "    )\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "    \n",
    "    val_loss, val_acc, val_f1, _, _ = eval_model(\n",
    "        model, val_loader, criterion, DEVICE\n",
    "    )\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_roberta_model.pt\")\n",
    "        print(\"Saved best model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5346 | Acc: 0.7713 | F1: 0.5541\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85     39586\n",
      "           1       0.65      0.49      0.55     16397\n",
      "\n",
      "    accuracy                           0.77     55983\n",
      "   macro avg       0.73      0.69      0.70     55983\n",
      "weighted avg       0.76      0.77      0.76     55983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "model.load_state_dict(torch.load(\"best_roberta_model.pt\"))\n",
    "test_loss, test_acc, test_f1, test_labels, test_preds = eval_model(\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | F1: {test_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(test_labels, test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
