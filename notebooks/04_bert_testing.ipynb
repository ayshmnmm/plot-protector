{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb10b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/electronic/Downloads/2025H1400069G/plot-protector-as-on-17-11-2025/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import kagglehub\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26984575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/electronic/.cache/kagglehub/datasets/rmisra/imdb-spoiler-dataset/versions/1\n",
      "movie_details shape: (1572, 7)\n",
      "reviews shape: (573913, 7)\n",
      "    movie_id  is_spoiler                                        review_text\n",
      "0  tt0111161        True  In its Oscar year, Shawshank Redemption (writt...\n",
      "1  tt0111161        True  The Shawshank Redemption is without a doubt on...\n",
      "2  tt0111161        True  I believe that this film is the best story eve...\n",
      "3  tt0111161        True  **Yes, there are SPOILERS here**This film has ...\n",
      "4  tt0111161        True  At the heart of this extraordinary movie is a ...\n"
     ]
    }
   ],
   "source": [
    "# Download dataset via kagglehub\n",
    "path = kagglehub.dataset_download(\"rmisra/imdb-spoiler-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load JSON lines into DataFrames\n",
    "movie_details = pd.read_json(os.path.join(path, \"IMDB_movie_details.json\"), lines=True)\n",
    "reviews       = pd.read_json(os.path.join(path, \"IMDB_reviews.json\"),       lines=True)\n",
    "\n",
    "print(\"movie_details shape:\", movie_details.shape)\n",
    "print(\"reviews shape:\", reviews.shape)\n",
    "print(reviews[[\"movie_id\", \"is_spoiler\", \"review_text\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b77a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Unescape HTML entities\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    \n",
    "    # Replace multiple whitespace with single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93c012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movie_id                                               text  is_spoiler\n",
      "0  tt0111161  In its Oscar year, Shawshank Redemption (writt...        True\n",
      "1  tt0111161  The Shawshank Redemption is without a doubt on...        True\n",
      "2  tt0111161  I believe that this film is the best story eve...        True\n",
      "3  tt0111161  **Yes, there are SPOILERS here**This film has ...        True\n",
      "4  tt0111161  At the heart of this extraordinary movie is a ...        True\n",
      "is_spoiler\n",
      "False    422989\n",
      "True     150924\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Merge movie metadata (optional) and build the final text column\n",
    "\n",
    "# We merge so that later we can experiment with adding plot_summary / synopsis if needed\n",
    "merged = reviews.merge(\n",
    "    movie_details[[\"movie_id\", \"plot_summary\", \"plot_synopsis\"]],\n",
    "    on=\"movie_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_movie\")\n",
    ")\n",
    "\n",
    "# # Option 1: Use ONLY review_text as input (recommended baseline)\n",
    "# def build_input_text(row):\n",
    "#     return clean_text(row[\"review_text\"])\n",
    "\n",
    "# Option 2 (later): concat review + plot_summary / synopsis:\n",
    "def build_input_text(row):\n",
    "    parts = [row[\"review_text\"], row.get(\"plot_summary\", \"\"), row.get(\"plot_synopsis\", \"\")]\n",
    "    parts = [clean_text(p) for p in parts if isinstance(p, str) and p.strip() != \"\"]\n",
    "    return \" \".join(parts)\n",
    "\n",
    "merged[\"text\"] = merged.apply(build_input_text, axis=1)\n",
    "\n",
    "# Keep only what we need\n",
    "data = merged[[\"movie_id\", \"text\", \"is_spoiler\"]].copy()\n",
    "\n",
    "# Drop rows with missing labels or empty text\n",
    "data = data.dropna(subset=[\"is_spoiler\"])\n",
    "data = data[data[\"text\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(data.head())\n",
    "print(data[\"is_spoiler\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "618d93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movie_id                                               text  label\n",
      "0  tt0111161  In its Oscar year, Shawshank Redemption (writt...      1\n",
      "1  tt0111161  The Shawshank Redemption is without a doubt on...      1\n",
      "2  tt0111161  I believe that this film is the best story eve...      1\n",
      "3  tt0111161  **Yes, there are SPOILERS here**This film has ...      1\n",
      "4  tt0111161  At the heart of this extraordinary movie is a ...      1\n",
      "label\n",
      "0    0.737026\n",
      "1    0.262974\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Encode labels as integers (0 = non-spoiler, 1 = spoiler)\n",
    "\n",
    "label_map = {False: 0, True: 1}\n",
    "data[\"label\"] = data[\"is_spoiler\"].map(label_map).astype(int)\n",
    "\n",
    "data = data[[\"movie_id\", \"text\", \"label\"]].reset_index(drop=True)\n",
    "print(data.head())\n",
    "print(data[\"label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747ae24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movies: 1572\n",
      "Train movies: 1257\n",
      "Val movies:   157\n",
      "Test movies:  158\n",
      "Train samples: 461323\n",
      "Val samples:   56607\n",
      "Test samples:  55983\n",
      "Train label distribution:\n",
      " label\n",
      "0    0.740917\n",
      "1    0.259083\n",
      "Name: proportion, dtype: float64\n",
      "Val label distribution:\n",
      " label\n",
      "0    0.734909\n",
      "1    0.265091\n",
      "Name: proportion, dtype: float64\n",
      "Test label distribution:\n",
      " label\n",
      "0    0.707108\n",
      "1    0.292892\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Movie-level train/val/test split (to avoid leakage across splits)\n",
    "\n",
    "# Get unique movie IDs\n",
    "movie_ids = data[\"movie_id\"].unique()\n",
    "print(\"Unique movies:\", len(movie_ids))\n",
    "\n",
    "# First: train vs temp (val+test)\n",
    "train_movie_ids, temp_movie_ids = train_test_split(\n",
    "    movie_ids,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Then: val vs test from temp\n",
    "val_movie_ids, test_movie_ids = train_test_split(\n",
    "    temp_movie_ids,\n",
    "    test_size=0.5,\n",
    "    random_state=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train movies:\", len(train_movie_ids))\n",
    "print(\"Val movies:  \", len(val_movie_ids))\n",
    "print(\"Test movies: \", len(test_movie_ids))\n",
    "\n",
    "# Map back to reviews\n",
    "train_df = data[data[\"movie_id\"].isin(train_movie_ids)].reset_index(drop=True)\n",
    "val_df   = data[data[\"movie_id\"].isin(val_movie_ids)].reset_index(drop=True)\n",
    "test_df  = data[data[\"movie_id\"].isin(test_movie_ids)].reset_index(drop=True)\n",
    "\n",
    "print(\"Train samples:\", len(train_df))\n",
    "print(\"Val samples:  \", len(val_df))\n",
    "print(\"Test samples: \", len(test_df))\n",
    "\n",
    "print(\"Train label distribution:\\n\", train_df[\"label\"].value_counts(normalize=True))\n",
    "print(\"Val label distribution:\\n\",   val_df[\"label\"].value_counts(normalize=True))\n",
    "print(\"Test label distribution:\\n\",  test_df[\"label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70656c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 128000\n",
      "Tokenizer type: <class 'transformers.models.deberta_v2.tokenization_deberta_v2.DebertaV2Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load DeBERTa-v3-base tokenizer (slow, explicit class)\n",
    "\n",
    "from transformers import DebertaV2Tokenizer\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "MAX_LEN = 256  # spoiler cues can be later in the review\n",
    "\n",
    "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Tokenizer type:\", type(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e534c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 461323\n",
      "Val dataset size: 56607\n",
      "Test dataset size: 55983\n",
      "input_ids torch.Size([256]) torch.int64\n",
      "attention_mask torch.Size([256]) torch.int64\n",
      "labels torch.Size([]) torch.int64\n",
      "Decoded text: In its Oscar year, Shawshank Redemption (written and directed by Frank Darabont, after the novella Rita Hayworth and the Shawshank Redemption, by Stephen King) was nominated for seven Academy Awards, and walked away with zero. Best Picture went to Forrest Gump, while Shawshank and Pulp Fiction were \"just happy to be nominated.\" Of course hindsight is 20/20, but while history looks back on Gump as a good film, Pulp and Redemption are remembered as some of the all-time best. Pulp, however, was a success from the word \"go,\" making a huge splash at Cannes and making its writer-director an American master after only two films. For Andy Dufresne and Co., success didn't come easy. Fortunately, failure wasn't a life sentence.After opening on 33 screens with take of $727,327, the $25M film fell fast from theatres and finished with a mere $28.3M. The reasons for failure are many. Firstly, the title is a clunker. While iconic to fans today, in 1994, people knew not and cared not what a 'Shawshank' was. On the DVD, Tim Robbins laughs recounting fans congratulating him on \"that 'Rickshaw' movie.\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: PyTorch Dataset for on-the-fly tokenization with DeBERTa-v3-base\n",
    "\n",
    "class IMDBSpoilerDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len: int = 256):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text  = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Remove batch dimension (since return_tensors=\"pt\" adds it)\n",
    "        item = {\n",
    "            \"input_ids\":      encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\":         torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        # DeBERTa-v3 does not need token_type_ids\n",
    "        return item\n",
    "\n",
    "train_dataset = IMDBSpoilerDataset(train_df, tokenizer, max_len=MAX_LEN)\n",
    "val_dataset   = IMDBSpoilerDataset(val_df,   tokenizer, max_len=MAX_LEN)\n",
    "test_dataset  = IMDBSpoilerDataset(test_df,  tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Val dataset size:\",   len(val_dataset))\n",
    "print(\"Test dataset size:\",  len(test_dataset))\n",
    "\n",
    "# Quick sanity check\n",
    "sample = train_dataset[0]\n",
    "for k, v in sample.items():\n",
    "    print(k, v.shape, v.dtype)\n",
    "print(\"Decoded text:\", tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True))\n",
    "print(\"Label:\", sample[\"labels\"].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667202e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "   ../data/de_berta_v3/train.csv\n",
      "   ../data/de_berta_v3/val.csv\n",
      "   ../data/de_berta_v3/test.csv\n",
      "   ../data/de_berta_v3/label_map.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Save preprocessed splits for DeBERTa-v3\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "save_dir = \"../data/de_berta_v3\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(save_dir, \"train.csv\")\n",
    "val_path   = os.path.join(save_dir, \"val.csv\")\n",
    "test_path  = os.path.join(save_dir, \"test.csv\")\n",
    "label_map_path = os.path.join(save_dir, \"label_map.json\")\n",
    "\n",
    "# Save splits\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "# Save label map (just for documentation / reuse)\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    json.dump(label_map, f)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  \", train_path)\n",
    "print(\"  \", val_path)\n",
    "print(\"  \", test_path)\n",
    "print(\"  \", label_map_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb185d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/electronic/Downloads/2025H1400069G/plot-protector-as-on-17-11-2025/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train shape: (461323, 3)\n",
      "Val shape: (56607, 3)\n",
      "Test shape: (55983, 3)\n",
      "    movie_id                                               text  label\n",
      "0  tt0111161  In its Oscar year, Shawshank Redemption (writt...      1\n",
      "1  tt0111161  The Shawshank Redemption is without a doubt on...      1\n",
      "2  tt0111161  I believe that this film is the best story eve...      1\n",
      "3  tt0111161  **Yes, there are SPOILERS here**This film has ...      1\n",
      "4  tt0111161  At the heart of this extraordinary movie is a ...      1\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and load preprocessed CSVs\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import DebertaV2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "data_dir = \"../data/de_berta_v3\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "val_df   = pd.read_csv(os.path.join(data_dir, \"val.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape:\",   val_df.shape)\n",
    "print(\"Test shape:\",  test_df.shape)\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fa8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 128000\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Tokenizer\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "MAX_LEN = 256\n",
    "\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f1e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset class (same as before)\n",
    "\n",
    "class IMDBSpoilerDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len: int = 256):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text  = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\":      encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\":         torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = IMDBSpoilerDataset(train_df, tokenizer, max_len=MAX_LEN)\n",
    "val_dataset   = IMDBSpoilerDataset(val_df,   tokenizer, max_len=MAX_LEN)\n",
    "test_dataset  = IMDBSpoilerDataset(test_df,  tokenizer, max_len=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c6526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([16, 256]) torch.int64\n",
      "attention_mask torch.Size([16, 256]) torch.int64\n",
      "labels torch.Size([16]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: DataLoaders (what was previously optional Cell 10)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ff67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Model + training imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7536eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Load DeBERTa-v3-base model for binary classification\n",
    "\n",
    "NUM_LABELS = 2\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"  # same as tokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "print(\"Model loaded on:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be1ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts: Counter({0: 341802, 1: 119521})\n",
      "Class weights: [0.674839526977607, 1.929882614770626]\n",
      "Total steps: 115332 | Warmup steps: 11533\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Class weights, optimizer, scheduler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Compute class weights from train_df\n",
    "label_counts = Counter(train_df[\"label\"].tolist())\n",
    "total = sum(label_counts.values())\n",
    "class_weights = [\n",
    "    total / (NUM_LABELS * label_counts.get(i, 1)) for i in range(NUM_LABELS)\n",
    "]\n",
    "\n",
    "print(\"Label counts:\", label_counts)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "EPOCHS = 4\n",
    "LR = 2e-5\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(WARMUP_RATIO * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"Total steps:\", total_steps, \"| Warmup steps:\", warmup_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27569e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Training and evaluation functions\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    pbar = tqdm(data_loader, desc=\"Train\", leave=False)\n",
    "    for batch in pbar:\n",
    "        input_ids      = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels         = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels_np)\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, acc, f1\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader, desc=\"Eval\", leave=False)\n",
    "        for batch in pbar:\n",
    "            input_ids      = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels         = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            epoch_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "            labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels_np)\n",
    "\n",
    "    avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "    return avg_loss, acc, f1, all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0344dfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.4742, Acc: 0.7838, F1: 0.4349\n",
      "Val   - Loss: 0.4590, Acc: 0.7834, F1: 0.5337\n",
      "✓ New best model saved with F1 = 0.5337\n",
      "======================================================================\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.4278, Acc: 0.8095, F1: 0.5441\n",
      "Val   - Loss: 0.4634, Acc: 0.7927, F1: 0.5211\n",
      "======================================================================\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3822, Acc: 0.8351, F1: 0.6281\n",
      "Val   - Loss: 0.4811, Acc: 0.7831, F1: 0.5585\n",
      "✓ New best model saved with F1 = 0.5585\n",
      "======================================================================\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3290, Acc: 0.8651, F1: 0.7098\n",
      "Val   - Loss: 0.5339, Acc: 0.7830, F1: 0.5500\n",
      "======================================================================\n",
      "Training completed.\n",
      "Best validation F1: 0.5585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 15: Main training loop\n",
    "\n",
    "BEST_MODEL_PATH = \"deberta_v3_best.pt\"\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        criterion,\n",
    "        DEVICE\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_f1, _, _ = eval_model(\n",
    "        model,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        DEVICE\n",
    "    )\n",
    "\n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"✓ New best model saved with F1 = {best_val_f1:.4f}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Training completed.\")\n",
    "print(f\"Best validation F1: {best_val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a256b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 0.5019, Acc: 0.7744, F1: 0.5839\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8207    0.8713    0.8452     39586\n",
      "           1     0.6349    0.5404    0.5839     16397\n",
      "\n",
      "    accuracy                         0.7744     55983\n",
      "   macro avg     0.7278    0.7058    0.7145     55983\n",
      "weighted avg     0.7663    0.7744    0.7687     55983\n",
      "\n",
      "Confusion matrix:\n",
      "[[34491  5095]\n",
      " [ 7536  8861]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cell 16: Test evaluation with the best saved model\n",
    "\n",
    "# Reload model weights from best checkpoint\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "best_model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
    "best_model.to(DEVICE)\n",
    "\n",
    "test_loss, test_acc, test_f1, test_labels, test_preds = eval_model(\n",
    "    best_model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Test - Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, F1: {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(test_labels, test_preds, digits=4))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
